# S-Expression Agent System

An explainable agent system prototype using S-expressions (S-expression) for task execution.

## 🌐 Languages / 言語

- 🇺🇸 **English** (This file)
- 🇯🇵 **[日本語 (Japanese)](README.md)**
- 📖 **[Other Languages / その他の言語](docs/README_languages.md)**

## Overview

This system provides an explainable agent architecture that executes tasks through S-expressions generated by LLMs.

### Key Features

- **Explainability**: Explicit execution plans through S-expressions
- **User Control**: Review and edit generated S-expressions
- **Context Awareness**: S-expression evaluation considering overall task context
- **MCP Ready**: Designed for future Model Context Protocol (MCP) extensions
- **LangChain Integration**: Tracing capabilities via langchain/langgraph

## Setup

### Prerequisites

- Python 3.12+
- uv (Python package manager)
- Local LLM server (OpenAI API compatible)

### Installation

```bash
# Clone the repository
git clone https://github.com/hama-jp/s_style_agent.git
cd s-style-agent

# Install dependencies with uv
uv sync
```

### LLM Configuration

This system supports multiple LLM providers. Configure using environment variables:

#### Local LLM (Default)

```bash
export LLM_BASE_URL="http://localhost:1234/v1"
export LLM_MODEL_NAME="local-model"
export LLM_API_KEY="dummy"
```

#### OpenAI

```bash
export LLM_BASE_URL="https://api.openai.com/v1"
export LLM_MODEL_NAME="gpt-4"
export LLM_API_KEY="your-openai-api-key-here"
```

Or for GPT-3.5 Turbo:

```bash
export LLM_BASE_URL="https://api.openai.com/v1"
export LLM_MODEL_NAME="gpt-3.5-turbo"
export LLM_API_KEY="your-openai-api-key-here"
```

#### Anthropic Claude

```bash
export LLM_BASE_URL="https://api.anthropic.com"
export LLM_MODEL_NAME="claude-3-sonnet-20240229"
export LLM_API_KEY="your-anthropic-api-key-here"
```

#### Additional Settings

```bash
# LLM behavior settings
export LLM_TEMPERATURE="0.3"  # Creativity level (0.0-1.0)

# System settings
export DEBUG="false"
export LANGSMITH_PROJECT="s-style-agent"
```

### MCP Configuration (Optional)

To use Model Context Protocol (MCP) compatible tools:

1. Copy `mcp.json.example` to create `mcp.json`
2. Configure required API keys
3. Tools will be automatically available at system startup

## Usage

### Basic Usage

```bash
# Start the system
uv run python -m s_style_agent.cli.main
```

### CLI Commands

- `/help` - Display help
- `/generate` - Generate S-expression using LLM
- `/parse` - Check S-expression syntax
- `/execute` - Execute S-expression
- `/history` - Show session history
- `/tools` - List available tools
- `/exit` - Exit system

### Usage Examples

```
> Calculate 2 plus 3
Generated S-expression: (calc "2 + 3")
Execute? (y/n/e=edit): y
Result: 5

> (seq (notify "Starting") (calc "10 * 5") (notify "Done"))
[NOTIFY] Starting
[NOTIFY] Done
Result: Done
```

## S-Expression Syntax

### Basic Syntax

- `(seq step1 step2 ...)` - Sequential execution
- `(par stepA stepB ...)` - Parallel execution
- `(if cond then else)` - Conditional branching
- `(let ((var expr) ...) body)` - Variable binding

### Available Tools

- `(notify "message")` - User notification
- `(calc "expression")` - Mathematical calculation
- `(search "query")` - Information search
- `(db-query "query")` - Database query

## Architecture

### Core Components

- **Parser**: S-expression parsing and validation
- **Evaluator**: Context-aware S-expression evaluation
- **Tools**: Extensible tool system for various operations
- **CLI**: Interactive command-line interface
- **API**: REST/WebSocket API server

### Execution Modes

- **Synchronous**: Traditional sequential execution
- **Asynchronous**: True parallel execution with task management

## Development

### Running Tests

```bash
# Run all tests
uv run python -m pytest s_style_agent/tests/

# Run specific test category
uv run python -m pytest s_style_agent/tests/test_mcp_*.py
```

### Project Structure

```
s_style_agent/
├── cli/           # Command-line interface
├── core/          # Core evaluation engine
├── api/           # REST/WebSocket API
├── tools/         # Tool implementations
├── mcp/           # MCP integration
├── config/        # Configuration management
└── tests/         # Test suite
```

## API Server

### Starting the API Server

```bash
# Start FastAPI server
uv run python -m s_style_agent.api.server
```

### API Endpoints

- `GET /` - Health check
- `POST /parse` - Parse S-expression
- `POST /execute` - Execute S-expression
- `POST /generate` - Generate S-expression from natural language
- `GET /status` - System status

### WebSocket Support

Real-time S-expression execution via WebSocket at `/ws/{session_id}`.

## MCP Integration

The system includes Model Context Protocol integration for extending capabilities:

- **Automatic Discovery**: MCP tools are automatically registered
- **Seamless Integration**: Use MCP tools directly in S-expressions
- **Error Handling**: Robust error handling and recovery

## Security

- No personal information or API keys in source code
- Environment variable based configuration
- Comprehensive `.gitignore` for sensitive files
- Safe execution environment for S-expressions

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make changes and add tests
4. Submit a pull request

## License

[Add your license information here]

## Acknowledgments

This project is inspired by the principles of explainable AI and symbolic computation.

---

🤖 **Generated with [Claude Code](https://claude.ai/code)**