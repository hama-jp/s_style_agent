#!/usr/bin/env python3
"""
æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆ - å…¨æ©Ÿèƒ½ã®å‹•ä½œç¢ºèª
"""

import os
import asyncio
from s_style_agent.core.schema_validator import LLMOutputGate
from s_style_agent.core.evaluator import ContextualEvaluator, Environment
from s_style_agent.core.parser import parse_s_expression

# LangSmithè¨­å®š
os.environ['LANGSMITH_PROJECT'] = 's-style-agent'
os.environ['LANGSMITH_TRACING'] = 'true'

async def test_end_to_end_workflow():
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    print("=== ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰çµ±åˆãƒ†ã‚¹ãƒˆ ===")
    
    # 1. LLMå‡ºåŠ›ã‚²ãƒ¼ãƒˆåˆæœŸåŒ–
    gate = LLMOutputGate(validation_level="strict")
    
    # 2. è©•ä¾¡å™¨åˆæœŸåŒ–
    evaluator = ContextualEvaluator()
    env = Environment()
    
    # 3. LLMå‡ºåŠ›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå®‰å…¨ãªSå¼ï¼‰
    safe_llm_outputs = [
        '(notify "ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")',
        '(seq (notify "è¨ˆç®—é–‹å§‹") (calc "2+2") (notify "è¨ˆç®—å®Œäº†"))',
        '(handle err (calc "1/0") (notify "ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¾ã—ãŸ"))',
        '(let [["x" 5]] (while (< x 8) (seq (notify x) (set x (+ x 1))) 5))',
        '(par (calc "10+5") (calc "20*2") (calc "100/4"))'
    ]
    
    print("\n1. å®‰å…¨ãªSå¼ã®å‡¦ç†:")
    for i, output in enumerate(safe_llm_outputs, 1):
        print(f"\n  {i}. LLMå‡ºåŠ›: {output}")
        
        # ã‚²ãƒ¼ãƒˆæ¤œè¨¼
        is_approved, parsed_expr, gate_errors = gate.validate_llm_output(output, "integration-test")
        
        if is_approved:
            print(f"      ğŸ” ã‚²ãƒ¼ãƒˆ: âœ… æ‰¿èª")
            
            try:
                # Så¼å®Ÿè¡Œ
                result = evaluator.evaluate_with_context(parsed_expr, env)
                print(f"      ğŸš€ å®Ÿè¡Œçµæœ: {result}")
            except Exception as e:
                print(f"      âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print(f"      ğŸ” ã‚²ãƒ¼ãƒˆ: âŒ æ‹’å¦")
            for error in gate_errors[:1]:
                print(f"         ç†ç”±: {error}")

async def test_security_blocking():
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ ===")
    
    gate = LLMOutputGate(validation_level="strict")
    
    # å±é™ºãªLLMå‡ºåŠ›ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    malicious_outputs = [
        '(eval "import os; os.system(\'rm -rf /\')")',
        '(__import__ "subprocess")',
        '(exec "dangerous_code")',
        '(while (< 1 2) (notify "ç„¡é™ãƒ«ãƒ¼ãƒ—") 50000)',  # åˆ¶é™è¶…é
        '(unknown_dangerous_op "payload")'
    ]
    
    print("\n2. å±é™ºãªSå¼ã®ãƒ–ãƒ­ãƒƒã‚¯:")
    blocked_count = 0
    for i, output in enumerate(malicious_outputs, 1):
        print(f"\n  {i}. å±é™ºãªå‡ºåŠ›: {output[:50]}...")
        
        is_approved, _, gate_errors = gate.validate_llm_output(output, "security-test")
        
        if not is_approved:
            blocked_count += 1
            print(f"      ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: âœ… æ­£ã—ããƒ–ãƒ­ãƒƒã‚¯")
            print(f"         ç†ç”±: {gate_errors[0] if gate_errors else 'Unknown'}")
        else:
            print(f"      ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: âŒ é€šéã—ã¦ã—ã¾ã£ãŸï¼")
    
    print(f"\n  ãƒ–ãƒ­ãƒƒã‚¯ç‡: {blocked_count}/{len(malicious_outputs)} ({blocked_count/len(malicious_outputs)*100:.0f}%)")

def test_schema_compliance():
    """ã‚¹ã‚­ãƒ¼ãƒæº–æ‹ ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ã‚¹ã‚­ãƒ¼ãƒæº–æ‹ ãƒ†ã‚¹ãƒˆ ===")
    
    from s_style_agent.core.schema_validator import SExpressionValidator
    validator = SExpressionValidator(validation_level="strict")
    
    # å®Ÿè£…æ¸ˆã¿æ§‹æ–‡ã®æ¤œè¨¼
    implemented_constructs = [
        # åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼
        ["seq", ["notify", "step1"], ["notify", "step2"]],
        ["par", ["calc", "1+1"], ["calc", "2+2"]],
        ["if", ["<", 5, 10], ["notify", "true"], ["notify", "false"]],
        ["handle", "err", ["unknown_op"], ["notify", "handled"]],
        ["while", ["<", "x", 3], ["set", "x", ["+", "x", 1]], 5],
        
        # å¤‰æ•°æ“ä½œ
        ["let", [["x", 42]], ["notify", "x"]],
        ["set", "counter", 0],
        
        # ç®—è¡“ãƒ»æ¯”è¼ƒ
        ["+", 1, 2, 3],
        ["<", 5, 10],
        
        # ãƒ„ãƒ¼ãƒ«
        ["notify", "message"],
        ["calc", "x^2+1"],
        ["math", "x^2", "diff", "x"],
        ["step_math", "integral of x", "integrate", "x"],
        ["ask_user", "è³ªå•", "var_name", "required"]
    ]
    
    print("\n3. å®Ÿè£…æ¸ˆã¿æ§‹æ–‡ã®æ¤œè¨¼:")
    valid_count = 0
    for i, construct in enumerate(implemented_constructs, 1):
        is_valid, errors = validator.validate(construct, source="schema_test", llm_model="test")
        
        if is_valid:
            valid_count += 1
            status = "âœ… æœ‰åŠ¹"
        else:
            status = "âŒ ç„¡åŠ¹"
        
        print(f"  {i:2d}. {str(construct)[:40]:<40} â†’ {status}")
        if errors and not is_valid:
            print(f"       ã‚¨ãƒ©ãƒ¼: {errors[0]}")
    
    print(f"\n  æº–æ‹ ç‡: {valid_count}/{len(implemented_constructs)} ({valid_count/len(implemented_constructs)*100:.0f}%)")

async def test_performance_and_stats():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨çµ±è¨ˆãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»çµ±è¨ˆãƒ†ã‚¹ãƒˆ ===")
    
    gate = LLMOutputGate(validation_level="permissive")
    
    # å¤§é‡ã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
    test_expressions = [
        '(notify "test")',
        '(calc "1+1")',
        '(eval "bad")',  # æ‹’å¦ã•ã‚Œã‚‹
        '(seq (notify "a") (notify "b"))',
        '(unknown_op "test")',  # æ‹’å¦ã•ã‚Œã‚‹
    ] * 20  # 100å›ã®ãƒ†ã‚¹ãƒˆ
    
    print("\n4. å¤§é‡æ¤œè¨¼ãƒ†ã‚¹ãƒˆ:")
    start_time = asyncio.get_event_loop().time()
    
    for expr in test_expressions:
        gate.validate_llm_output(expr, "perf-test")
    
    end_time = asyncio.get_event_loop().time()
    processing_time = end_time - start_time
    
    stats = gate.get_stats()
    print(f"  å‡¦ç†æ™‚é–“: {processing_time:.3f}ç§’")
    print(f"  å‡¦ç†é€Ÿåº¦: {stats['total']/processing_time:.1f} expr/sec")
    print(f"  çµ±è¨ˆ: {stats}")

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ Så¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*60)
    
    await test_end_to_end_workflow()
    await test_security_blocking()
    test_schema_compliance()
    await test_performance_and_stats()
    
    print("\n" + "="*60)
    print("âœ… æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
    print("\nğŸ“‹ å®Ÿè£…å®Œäº†æ©Ÿèƒ½:")
    print("  âœ… Så¼AST JSON Schema")
    print("  âœ… LLMå‡ºåŠ›ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚²ãƒ¼ãƒˆ")
    print("  âœ… ãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼æ¤œè¨¼")
    print("  âœ… try/catch (handle) æ§‹æ–‡")
    print("  âœ… while/loop æ§‹æ–‡")
    print("  âœ… ä¸¦åˆ—ãƒ»éåŒæœŸå®Ÿè¡Œ")
    print("  âœ… LangSmithãƒˆãƒ¬ãƒ¼ã‚¹çµ±åˆ")
    print("\nğŸ“Š LangSmithã§è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ç¢ºèª:")
    print("   https://smith.langchain.com/")

if __name__ == "__main__":
    asyncio.run(main())